{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4002aca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "import pickle\n",
    "from sklearn.feature_selection import mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a06e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/ISCX_training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8e8f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_columns=list(set(my_columns)-set(['Unnamed: 0','Label','SrcAddr', 'DstAddr', 'Proto', 'Sport', 'Dport', 'State', 'StartTime', 'LastTime','SrcMac', 'DstMac']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ac0e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f547697",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(filtered_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb48855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load the ig_scores array\n",
    "ctu_ig_scores = np.load('info_gain_result/ctu_ig_scores.npy')\n",
    "iscx_ig_scores=np.load('info_gain_result/iscx_ig_scores.npy')\n",
    "isot_ig_scores=np.load('info_gain_result/isot_ig_scores.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f64da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "labels = ['sTos', 'dTos', 'SrcWin', 'DstWin', 'sHops', 'dHops', 'sTtl', 'dTtl', 'TcpRtt', 'SynAck', 'AckDat', 'SrcPkts',\n",
    "          'DstPkts', 'SrcBytes', 'DstBytes', 'SAppBytes', 'DAppBytes', 'Dur', 'TotPkts', 'TotBytes', 'TotAppByte',\n",
    "          'Rate', 'SrcRate', 'DstRate']\n",
    "\n",
    "# Function to create a bar plot with bold labels and increased font size\n",
    "def plot_ig_scores(data, title, dataset_name):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.bar(range(len(data)), data)\n",
    "    plt.xlabel('Features', fontsize=14, fontweight='bold')\n",
    "    plt.ylabel('Information Gain', fontsize=14, fontweight='bold')\n",
    "    plt.title(title + ' - ' + dataset_name, fontsize=14, fontweight='bold')\n",
    "    plt.xticks(range(len(labels)), labels, rotation=45, fontsize=10, fontweight='bold')\n",
    "    plt.yticks(fontsize=12, fontweight='bold')\n",
    "    plt.show()\n",
    "\n",
    "# Plotting for each dataset\n",
    "plot_ig_scores(iscx_ig_scores, 'Information Gain Scores', 'ISCX Dataset')\n",
    "plot_ig_scores(isot_ig_scores, 'Information Gain Scores', 'ISOT Dataset')\n",
    "\n",
    "# Calculate average information gain and plot\n",
    "avg_ig_scores = np.mean([ctu_ig_scores, iscx_ig_scores, isot_ig_scores], axis=0)\n",
    "plot_ig_scores(avg_ig_scores, 'Average Information Gain Scores', 'Average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef914ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Assuming you have ctu_ig_scores, iscx_ig_scores, and isot_ig_scores as arrays\n",
    "labels = ['sTos', 'dTos', 'SrcWin', 'DstWin', 'sHops', 'dHops', 'sTtl', 'dTtl', 'TcpRtt', 'SynAck', 'AckDat', 'SrcPkts',\n",
    "          'DstPkts', 'SrcBytes', 'DstBytes', 'SAppBytes', 'DAppBytes', 'Dur', 'TotPkts', 'TotBytes', 'TotAppByte',\n",
    "          'Rate', 'SrcRate', 'DstRate']\n",
    "\n",
    "\n",
    "\n",
    "# Bar plot for iscx_ig_scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(iscx_ig_scores)), iscx_ig_scores)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Information Gain')\n",
    "plt.title('Information Gain Scores - ISCX Dataset')\n",
    "plt.xticks(range(len(labels)), labels, rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Bar plot for isot_ig_scores\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(isot_ig_scores)), isot_ig_scores)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Information Gain')\n",
    "plt.title('Information Gain Scores - ISOT Dataset')\n",
    "plt.xticks(range(len(labels)), labels, rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Average information gain and bar plot\n",
    "avg_ig_scores = np.mean([iscx_ig_scores, isot_ig_scores], axis=0)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(avg_ig_scores)), avg_ig_scores)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Average Information Gain')\n",
    "plt.title('Average Information Gain Scores')\n",
    "plt.xticks(range(len(labels)), labels, rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e0f1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_thresholds = np.linspace(0, max(avg_ig_scores), num=20)\n",
    "print(potential_thresholds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d726c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_threshold(filename):\n",
    "\n",
    "    avg_ig_scores=np.array([0.00040332, 0.00161157, 0.12017481, 0.04676683, 0.14954481,\\\n",
    "        0.05875154, 0.15869463, 0.113153  , 0.04962509, 0.04982147,\\\n",
    "        0.04508607, 0.08877224, 0.07776499, 0.13168685, 0.0932552 ,\\\n",
    "        0.01016336, 0.00898032, 0.12269696, 0.08166047, 0.13271621,\\\n",
    "        0.01046889, 0.11122463, 0.08523292, 0.0630542 ])\n",
    "    potential_thresholds = np.linspace(0, max(avg_ig_scores), num=20)\n",
    "    data=pd.read_csv(r\"data/isot_botnet.csv\")\n",
    "    data_sel=data[['sTos', 'dTos', 'SrcWin', 'DstWin', 'sHops', 'dHops', 'sTtl', 'dTtl', 'TcpRtt', 'SynAck', 'AckDat', 'SrcPkts',\\\n",
    "    'DstPkts', 'SrcBytes', 'DstBytes', 'SAppBytes', 'DAppBytes', 'Dur', 'TotPkts', 'TotBytes', 'TotAppByte',\\\n",
    "    'Rate', 'SrcRate', 'DstRate']]\n",
    "    X_train=data_sel.values\n",
    "    y_train=data['Label'].tolist()\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.99, random_state=42)\n",
    "    best_threshold = None\n",
    "    best_score = -np.inf  # assuming a higher score is better, adjust if necessary\n",
    "    threshold_scores=[]\n",
    "    for threshold in potential_thresholds:\n",
    "        print(threshold)\n",
    "        # select features with IG above the threshold\n",
    "        selected_features = np.where(avg_ig_scores >= threshold)[0]\n",
    "        X_train_selected = X_train[:, selected_features]\n",
    "        \n",
    "        # train model using selected features\n",
    "        model = RandomForestClassifier()  # replace with your model\n",
    "        model.fit(X_train_selected, y_train)\n",
    "\n",
    "        # perform cross-validation on the validation set\n",
    "        cv_score = cross_val_score(model, X_train_selected, y_train, cv=2, scoring='f1').mean()\n",
    "        print(\"This is the score we got\",cv_score)\n",
    "        threshold_scores.append((threshold,cv_score ))\n",
    "        # update best_threshold and best_score if this model is better\n",
    "        if cv_score > best_score:\n",
    "            best_threshold = threshold\n",
    "            best_score = cv_score\n",
    "    # Save the list to a file\n",
    "    with open('feature_sel_result\\/'+filename+'_sel_result.pickle', \"wb\") as file:\n",
    "        pickle.dump(threshold_scores, file)\n",
    "    print(f'Best threshold: {best_threshold}, F1 Score: {best_score}')\n",
    "    return threshold_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fefcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mutual_info(filename):\n",
    "    data=pd.read_csv(filename,index_col=[0])\n",
    "    X=data[['sTos', 'dTos', 'SrcWin', 'DstWin', 'sHops', 'dHops', 'sTtl', 'dTtl',\n",
    "        'TcpRtt', 'SynAck', 'AckDat', 'SrcPkts', 'DstPkts', 'SrcBytes',\n",
    "        'DstBytes', 'SAppBytes', 'DAppBytes', 'Dur', 'TotPkts', 'TotBytes',\n",
    "        'TotAppByte', 'Rate', 'SrcRate', 'DstRate']]\n",
    "    #ctu = ctu.drop(\"Unnamed: 0\", axis=1)\n",
    "    #X = iscx.drop(['SrcAddr', 'DstAddr','Proto','Sport','Dport','State','StartTime','LastTime','Label'], axis=1) # Drop the target column\n",
    "    y = data['Label']\n",
    "    ig_scores_data = mutual_info_classif(X , y)\n",
    "    np.save('info_gain_result/iscx_ig_scores.npy',ig_scores_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a3f391",
   "metadata": {},
   "outputs": [],
   "source": [
    "iscx_thresholds=find_best_threshold('path_to your data')\n",
    "isot_thresholds=find_best_threshold('path to your data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611a6025",
   "metadata": {},
   "outputs": [],
   "source": [
    "isot_scores=get_mutual_info('path to your data')\n",
    "iscx_scores=get_mutual_info('path to your data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2757758d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=[10, 8])\n",
    "plt.plot(iscx_thresholds, iscx_scores, label='ISCX')\n",
    "plt.plot(isot_thresholds, isot_scores, label='ISOT')\n",
    "\n",
    "# Annotations with increased font size and bold font\n",
    "for i in range(len(iscx_scores)):\n",
    "    plt.annotate(round(iscx_scores[i], 2), (iscx_thresholds[i], iscx_scores[i]), fontsize=10, fontweight='bold')\n",
    "for i in range(len(isot_scores)):\n",
    "    plt.annotate(round(isot_scores[i], 2), (isot_thresholds[i], isot_scores[i]), fontsize=10, fontweight='bold')\n",
    "\n",
    "# Setting font size and font weight for labels and title\n",
    "plt.xlabel('Threshold', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('F1 Score', fontsize=14, fontweight='bold')\n",
    "plt.title('F1 Scores vs Thresholds', fontsize=16, fontweight='bold')\n",
    "plt.xticks(fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=12, fontweight='bold')\n",
    "\n",
    "# Enhancing the legend and grid\n",
    "plt.legend(fontsize=12, title_fontsize=12)\n",
    "plt.grid(True)\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477abf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_indices = np.where(avg_ig_scores >= 0.09)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c158fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = [labels[i] for i in selected_features_indices]\n",
    "\n",
    "print(selected_features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
